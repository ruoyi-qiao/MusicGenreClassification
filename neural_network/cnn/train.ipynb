{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 14:10:05.748068: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 14:10:06.543889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Input' from 'keras.models' (/root/miniconda3/lib/python3.8/site-packages/keras/models/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential, Input,Model, load_model\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout, Flatten, LSTM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, MaxPool1D, GaussianNoise, GlobalMaxPooling1D\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Input' from 'keras.models' (/root/miniconda3/lib/python3.8/site-packages/keras/models/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os, sys, cv2\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential, Input,Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, MaxPool1D, GaussianNoise, GlobalMaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the .npz file of features\n",
    "f = np.load(os.getcwd()+\"/MusicFeatures.npz\")\n",
    "S = f['spec']\n",
    "mfcc = f['mfcc']\n",
    "mel = f['mel']\n",
    "chroma = f['chroma']\n",
    "y = f['target']\n",
    "\n",
    "# split train-test data\n",
    "S_train, S_test, mfcc_train, mfcc_test, mel_train, mel_test, chroma_train, chroma_test, y_train, y_test = train_test_split(S, mfcc, mel, chroma, y, test_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "maximum1 = np.amax(S_train)\n",
    "S_train = S_train/np.amax(maximum1)\n",
    "S_test = S_test/np.amax(maximum1)\n",
    "\n",
    "S_train = S_train.astype(np.float32)\n",
    "S_test = S_test.astype(np.float32)\n",
    "\n",
    "N, row, col = S_train.shape\n",
    "S_train = S_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = S_test.shape\n",
    "S_test = S_test.reshape((N, row, col, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "newtrain_mfcc = np.empty((mfcc_train.shape[0], 120, 600))\n",
    "newtest_mfcc = np.empty((mfcc_test.shape[0], 120, 600))\n",
    "\n",
    "for i in range(mfcc_train.shape[0]) :\n",
    "    curr = mfcc_train[i]\n",
    "    curr = cv2.resize(curr, (600, 120))\n",
    "    newtrain_mfcc[i] = curr\n",
    "\n",
    "mfcc_train = newtrain_mfcc\n",
    "\n",
    "for i in range(mfcc_test.shape[0]) :\n",
    "\n",
    "  curr = mfcc_test[i]\n",
    "  curr = cv2.resize(curr, (600, 120))\n",
    "  newtest_mfcc[i] = curr\n",
    "\n",
    "mfcc_test = newtest_mfcc\n",
    "\n",
    "mfcc_train = mfcc_train.astype(np.float32)\n",
    "mfcc_test = mfcc_test.astype(np.float32)\n",
    "\n",
    "N, row, col = mfcc_train.shape\n",
    "mfcc_train = mfcc_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = mfcc_test.shape\n",
    "mfcc_test = mfcc_test.reshape((N, row, col, 1))\n",
    "\n",
    "mean_data = np.mean(mfcc_train)\n",
    "std_data = np.std(mfcc_train)\n",
    "\n",
    "mfcc_train = (mfcc_train - mean_data)/ std_data\n",
    "mfcc_test = (mfcc_test - mean_data)/ std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-Spectrogram\n",
    "\n",
    "maximum = np.amax(mel_train)\n",
    "mel_train = mel_train/np.amax(maximum)\n",
    "mel_test = mel_test/np.amax(maximum)\n",
    "\n",
    "mel_train = mel_train.astype(np.float32)\n",
    "mel_test = mel_test.astype(np.float32)\n",
    "\n",
    "N, row, col = mel_train.shape\n",
    "mel_train = mel_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = mel_test.shape\n",
    "mel_test = mel_test.reshape((N, row, col, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Spectrogram train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_spectrogram_train_test.npz\", S_train= S_train, S_test= S_test, y_train = y_train, y_test= y_test)\n",
    "\n",
    "# Save MFCC train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_mfcc_train_test.npz\", mfcc_train= mfcc_train, mfcc_test= mfcc_test, y_train = y_train, y_test= y_test)\n",
    "\n",
    "# Save Mel-Spectrogram train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_mel_train_test.npz\", mel_train= mel_train, mel_test= mel_test, y_train = y_train, y_test= y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spectrogram Train-test data\n",
    "spec_file = np.load(os.getcwd()+\"/new_spectrogram_train_test.npz\")\n",
    "\n",
    "# Model 1 for Spectrogram\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= S_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train Model 1\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/new_spec_model_spectrogram1_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "model.fit(S_train, y_train, epochs= 100, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/new_spec_model_spectrogram1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.getcwd() + \"/models/new_model_spectrogram1.h5\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# # Testing Accuracy\n",
    "y_pred = model.predict(S_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Test Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = [\"Blues\", \"Classical\", \"Country\", \"Disco\", \"Hiphop\", \"Jazz\", \"Metal\", \"Pop\", \"Reggae\", \"Rock\"]\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_spec_conf_mat1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram Model 2\n",
    "\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= S_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train Model 2\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/new_spec_model_spectrogram2_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "model.fit(S_train, y_train, epochs= 100, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/new_spec_model_spectrogram2.h5\")\n",
    "\n",
    "model = load_model(os.getcwd() + \"/models/new_model_spectrogram2.h5\")\n",
    "\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = [\"Blues\", \"Classical\", \"Country\", \"Disco\", \"Hiphop\", \"Jazz\", \"Metal\", \"Pop\", \"Reggae\", \"Rock\"]\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_spec_conf_mat2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFCC file\n",
    "mfcc_file = np.load(os.getcwd()+\"/new_mfcc_train_test.npz\")\n",
    "mfcc_train = mfcc_file['mfcc_train']\n",
    "mfcc_test = mfcc_file['mfcc_test']\n",
    "y_train = mfcc_file['y_train']\n",
    "y_test = mfcc_file['y_test']\n",
    "\n",
    "# Define model for MFCC\n",
    "def get_model() :\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Conv2D(32, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Conv2D(64, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(256, activation= 'tanh'))\n",
    "    model.add(Dense(256, activation= 'tanh'))\n",
    "    model.add(Dense(64, activation= 'tanh'))\n",
    "    model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "    model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the majority vote\n",
    "def get_majority(pred) :\n",
    "  N = len(pred[0])\n",
    "  vote = []\n",
    "  for i in range(N) :\n",
    "    candidates = [x[i] for x in pred]\n",
    "    candidates = np.array(candidates)\n",
    "    uniq, freq = np.unique(candidates, return_counts= True)\n",
    "    vote.append(uniq[np.argmax(freq)])\n",
    "\n",
    "    vote = np.array(vote)\n",
    "\n",
    "    return vote\n",
    "\n",
    "# Train Model 1\n",
    "\n",
    "model1 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model1.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model1.save(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "\n",
    "# Train Model 2\n",
    "\n",
    "model2 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model2.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model2.save(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "\n",
    "# Train Model 3\n",
    "\n",
    "model3 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model3.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model3.save(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "model1 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "model2 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "model3 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "y_pred1 = model1.predict(mfcc_train)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "y_pred2 = model2.predict(mfcc_train)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "y_pred3 = model3.predict(mfcc_train)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "y_pred = [y_pred1, y_pred2, y_pred3]\n",
    "\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Test Model\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "y_pred1 = model1.predict(mfcc_test)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "y_pred2 = model2.predict(mfcc_test)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "y_pred3 = model3.predict(mfcc_test)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "y_pred = [y_pred1, y_pred2, y_pred3]\n",
    "\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = [\"Blues\", \"Classical\", \"Country\", \"Disco\", \"Hiphop\", \"Jazz\", \"Metal\", \"Pop\", \"Reggae\", \"Rock\"]\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_ensemble_mfcc_conf_mat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-Sprectrogram\n",
    "\n",
    "# Load npz file of Mel-Spectrogram\n",
    "file = np.load(os.getcwd()+\"/new_mel_train_test.npz\")\n",
    "mel_train = file['mel_train']\n",
    "mel_test = file['mel_test']\n",
    "y_train = file['y_train']\n",
    "y_test = file['y_test']\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= mel_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train Model\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/ensemble_model_melspectrogram1_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "model.fit(mel_train, y_train, epochs= 200, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")\n",
    "\n",
    "# Load the model\n",
    "model = load_model(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")\n",
    "\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(mel_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Testing Accuracy\n",
    "y_pred = model.predict(mel_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "print(\"Testing Accuracy\", acc)\n",
    "\n",
    "class_names = [\"Blues\", \"Classical\", \"Country\", \"Disco\", \"Hiphop\", \"Jazz\", \"Metal\", \"Pop\", \"Reggae\", \"Rock\"]\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/ensemble_mel_conf_mat1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spectrogram model 1\n",
    "spec_file = np.load(os.getcwd()+\"/new_spectrogram_train_test.npz\")\n",
    "\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model1 = load_model(os.getcwd() + \"/models/new_spec_model_spectrogram1.h5\")\n",
    "\n",
    "# Load Spectrogram model 2\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model2 = load_model(os.getcwd() + \"/models/new_spec_model_spectrogram2.h5\")\n",
    "\n",
    "# Load MFCC model 1,2 and 3\n",
    "mfcc_file = np.load(os.getcwd()+\"/new_mfcc_train_test.npz\")\n",
    "mfcc_train = mfcc_file['mfcc_train']\n",
    "mfcc_test = mfcc_file['mfcc_test']\n",
    "y_train = mfcc_file['y_train']\n",
    "y_test = mfcc_file['y_test']\n",
    "\n",
    "model3 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "model4 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "model5 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")\n",
    "\n",
    "# Load Mel-spectrogram model\n",
    "file = np.load(os.getcwd()+\"/new_mel_train_test.npz\")\n",
    "mel_train = file['mel_train']\n",
    "mel_test = file['mel_test']\n",
    "y_train = file['y_train']\n",
    "y_test = file['y_test']\n",
    "\n",
    "model6 = load_model(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "# Spectrogram model 1\n",
    "y_pred1 = model1.predict(S_train)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "# Spectrogram model 2\n",
    "y_pred2 = model2.predict(S_train)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "# MFCC model 1\n",
    "y_pred3 = model3.predict(mfcc_train)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "# MFCC model 2\n",
    "y_pred4 = model4.predict(mfcc_train)\n",
    "y_pred4 = np.argmax(y_pred4, axis= -1)\n",
    "\n",
    "# MFCC model 3\n",
    "y_pred5 = model5.predict(mfcc_train)\n",
    "y_pred5 = np.argmax(y_pred5, axis= -1)\n",
    "\n",
    "# Mel-spectrogram \n",
    "y_pred6 = model6.predict(mel_train)\n",
    "y_pred6 = np.argmax(y_pred6, axis= -1)\n",
    "\n",
    "# Get majority vote\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6]\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Training Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Test Model\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "# Spectrogram model 1\n",
    "y_pred1 = model1.predict(S_test)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "# Spectrogram model 2\n",
    "y_pred2 = model2.predict(S_test)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "# MFCC model 1\n",
    "y_pred3 = model3.predict(mfcc_test)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "# MFCC model 2\n",
    "y_pred4 = model4.predict(mfcc_test)\n",
    "y_pred4 = np.argmax(y_pred4, axis= -1)\n",
    "\n",
    "# MFCC model 3\n",
    "y_pred5 = model5.predict(mfcc_test)\n",
    "y_pred5 = np.argmax(y_pred5, axis= -1)\n",
    "\n",
    "# Mel-Spectrogram \n",
    "y_pred6 = model6.predict(mel_test)\n",
    "y_pred6 = np.argmax(y_pred6, axis= -1)\n",
    "\n",
    "# Get majority vote\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6]\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = [\"Blues\", \"Classical\", \"Country\", \"Disco\", \"Hiphop\", \"Jazz\", \"Metal\", \"Pop\", \"Reggae\", \"Rock\"]\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_ensemble_conf_mat.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
