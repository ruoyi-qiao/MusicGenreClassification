{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, cv2\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential, Input,Model, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, MaxPool1D, GaussianNoise, GlobalMaxPooling1D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import tensorflow\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the .npz file of features\n",
    "f = np.load(os.getcwd()+\"/MusicFeatures.npz\")\n",
    "S = f['spec']\n",
    "mfcc = f['mfcc']\n",
    "mel = f['mel']\n",
    "chroma = f['chroma']\n",
    "y = f['target']\n",
    "\n",
    "# split train-test data\n",
    "S_train, S_test, mfcc_train, mfcc_test, mel_train, mel_test, chroma_train, chroma_test, y_train, y_test = train_test_split(S, mfcc, mel, chroma, y, test_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram\n",
    "maximum1 = np.amax(S_train)\n",
    "S_train = S_train/np.amax(maximum1)\n",
    "S_test = S_test/np.amax(maximum1)\n",
    "\n",
    "S_train = S_train.astype(np.float32)\n",
    "S_test = S_test.astype(np.float32)\n",
    "\n",
    "N, row, col = S_train.shape\n",
    "S_train = S_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = S_test.shape\n",
    "S_test = S_test.reshape((N, row, col, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "newtrain_mfcc = np.empty((mfcc_train.shape[0], 120, 600))\n",
    "newtest_mfcc = np.empty((mfcc_test.shape[0], 120, 600))\n",
    "\n",
    "for i in range(mfcc_train.shape[0]) :\n",
    "    curr = mfcc_train[i]\n",
    "    curr = cv2.resize(curr, (600, 120))\n",
    "    newtrain_mfcc[i] = curr\n",
    "\n",
    "mfcc_train = newtrain_mfcc\n",
    "\n",
    "for i in range(mfcc_test.shape[0]) :\n",
    "\n",
    "  curr = mfcc_test[i]\n",
    "  curr = cv2.resize(curr, (600, 120))\n",
    "  newtest_mfcc[i] = curr\n",
    "\n",
    "mfcc_test = newtest_mfcc\n",
    "\n",
    "mfcc_train = mfcc_train.astype(np.float32)\n",
    "mfcc_test = mfcc_test.astype(np.float32)\n",
    "\n",
    "N, row, col = mfcc_train.shape\n",
    "mfcc_train = mfcc_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = mfcc_test.shape\n",
    "mfcc_test = mfcc_test.reshape((N, row, col, 1))\n",
    "\n",
    "mean_data = np.mean(mfcc_train)\n",
    "std_data = np.std(mfcc_train)\n",
    "\n",
    "mfcc_train = (mfcc_train - mean_data)/ std_data\n",
    "mfcc_test = (mfcc_test - mean_data)/ std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-Spectrogram\n",
    "\n",
    "maximum = np.amax(mel_train)\n",
    "mel_train = mel_train/np.amax(maximum)\n",
    "mel_test = mel_test/np.amax(maximum)\n",
    "\n",
    "mel_train = mel_train.astype(np.float32)\n",
    "mel_test = mel_test.astype(np.float32)\n",
    "\n",
    "N, row, col = mel_train.shape\n",
    "mel_train = mel_train.reshape((N, row, col, 1))\n",
    "\n",
    "N, row, col = mel_test.shape\n",
    "mel_test = mel_test.reshape((N, row, col, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Spectrogram train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_spectrogram_train_test.npz\", S_train= S_train, S_test= S_test, y_train = y_train, y_test= y_test)\n",
    "\n",
    "# Save MFCC train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_mfcc_train_test.npz\", mfcc_train= mfcc_train, mfcc_test= mfcc_test, y_train = y_train, y_test= y_test)\n",
    "\n",
    "# Save Mel-Spectrogram train-test\n",
    "np.savez_compressed(os.getcwd()+\"/new_mel_train_test.npz\", mel_train= mel_train, mel_test= mel_test, y_train = y_train, y_test= y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import set_session\n",
    "from keras.backend import clear_session\n",
    "from keras.backend import get_session\n",
    "import tensorflow as tf\n",
    "import gc\n",
    " \n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    " \n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    " \n",
    "    print(gc.collect()) # if it does something you should see a number as output\n",
    " \n",
    "    # use the same config as you used to create the session\n",
    "    config = tf.compat.v1.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 3.16 GiB for an array with shape (848208000,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25864\\2693093376.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Model 1 for Spectrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mS_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mS_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'S_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspec_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py37_tf27\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    254\u001b[0m                 return format.read_array(bytes,\n\u001b[0;32m    255\u001b[0m                                          \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                                          pickle_kwargs=self.pickle_kwargs)\n\u001b[0m\u001b[0;32m    257\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py37_tf27\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    768\u001b[0m             \u001b[1;31m# not correctly instantiate zero-width string dtypes; see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m             \u001b[1;31m# https://github.com/numpy/numpy/pull/6430\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 770\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemsize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 3.16 GiB for an array with shape (848208000,) and data type float32"
     ]
    }
   ],
   "source": [
    "# Load Spectrogram Train-test data\n",
    "spec_file = np.load(os.getcwd()+\"/new_spectrogram_train_test.npz\")\n",
    "\n",
    "# Model 1 for Spectrogram\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= S_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(8, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train Model 1\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/new_spec_model_spectrogram1_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "reset_keras()\n",
    "model.fit(S_train, y_train, epochs= 100, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/new_spec_model_spectrogram1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at d:\\Desktop\\src\\Github\\MusicGenreClassification\\neural_network\\cnn\\models\\new_spec_model_spectrogram1.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25864\\1428750742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\models\\\\new_spec_model_spectrogram1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Training Accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py37_tf27\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\py37_tf27\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             raise ImportError(\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at d:\\Desktop\\src\\Github\\MusicGenreClassification\\neural_network\\cnn\\models\\new_spec_model_spectrogram1.h5"
     ]
    }
   ],
   "source": [
    "model = load_model(os.getcwd() + \"/models/new_spec_model_spectrogram1.h5\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# # Testing Accuracy\n",
    "y_pred = model.predict(S_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Test Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = ['Experimental', 'Rock', 'Instrumental', 'International', 'Hip-Hop', 'Folk', 'Electronic', 'Pop']\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (8,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_spec_conf_mat1.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram Model 2\n",
    "\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= S_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(8, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train Model 2\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/new_spec_model_spectrogram2_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "model.fit(S_train, y_train, epochs= 100, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/new_spec_model_spectrogram2.h5\")\n",
    "\n",
    "model = load_model(os.getcwd() + \"/models/new_model_spectrogram2.h5\")\n",
    "\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(S_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = ['Experimental', 'Rock', 'Instrumental', 'International', 'Hip-Hop', 'Folk', 'Electronic', 'Pop']\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_spec_conf_mat2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MFCC file\n",
    "mfcc_file = np.load(os.getcwd()+\"/new_mfcc_train_test.npz\")\n",
    "mfcc_train = mfcc_file['mfcc_train']\n",
    "mfcc_test = mfcc_file['mfcc_test']\n",
    "y_train = mfcc_file['y_train']\n",
    "y_test = mfcc_file['y_test']\n",
    "\n",
    "# Define model for MFCC\n",
    "def get_model() :\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Conv2D(32, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Conv2D(64, (3,3), input_shape= mfcc_train[0].shape, activation= 'tanh', padding= 'same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((4,6), padding= 'same'))\n",
    "    model.add(Flatten())\n",
    "    # model.add(Dense(256, activation= 'tanh'))\n",
    "    model.add(Dense(256, activation= 'tanh'))\n",
    "    model.add(Dense(64, activation= 'tanh'))\n",
    "    model.add(Dense(8, activation= 'softmax'))\n",
    "\n",
    "    model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the majority vote\n",
    "def get_majority(pred) :\n",
    "  N = len(pred[0])\n",
    "  vote = []\n",
    "  for i in range(N) :\n",
    "    candidates = [x[i] for x in pred]\n",
    "    candidates = np.array(candidates)\n",
    "    uniq, freq = np.unique(candidates, return_counts= True)\n",
    "    vote.append(uniq[np.argmax(freq)])\n",
    "\n",
    "    vote = np.array(vote)\n",
    "\n",
    "    return vote\n",
    "\n",
    "# Train Model 1\n",
    "\n",
    "model1 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model1.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model1.save(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "\n",
    "# Train Model 2\n",
    "\n",
    "model2 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model2.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model2.save(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "\n",
    "# Train Model 3\n",
    "\n",
    "model3 = get_model()\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "for train_index, val_index in kf.split(mfcc_train, np.argmax(y_train, axis= -1)):\n",
    "\n",
    "    kf_mfcc_train = mfcc_train[train_index]\n",
    "    kf_X_val = mfcc_train[val_index]\n",
    "    kf_y_train = y_train[train_index]\n",
    "    kf_y_val = y_train[val_index]\n",
    "\n",
    "    model3.fit(kf_mfcc_train, kf_y_train, validation_data= (kf_X_val, kf_y_val), epochs= 30, batch_size= 30, verbose= 1)\n",
    "    model3.save(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "model1 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "model2 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "model3 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")\n",
    "\n",
    "# Training Accuracy\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "y_pred1 = model1.predict(mfcc_train)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "y_pred2 = model2.predict(mfcc_train)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "y_pred3 = model3.predict(mfcc_train)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "y_pred = [y_pred1, y_pred2, y_pred3]\n",
    "\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Test Model\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "y_pred1 = model1.predict(mfcc_test)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "y_pred2 = model2.predict(mfcc_test)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "y_pred3 = model3.predict(mfcc_test)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "y_pred = [y_pred1, y_pred2, y_pred3]\n",
    "\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = ['Experimental', 'Rock', 'Instrumental', 'International', 'Hip-Hop', 'Folk', 'Electronic', 'Pop']\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_ensemble_mfcc_conf_mat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mel-Sprectrogram\n",
    "\n",
    "# Load npz file of Mel-Spectrogram\n",
    "file = np.load(os.getcwd()+\"/new_mel_train_test.npz\")\n",
    "mel_train = file['mel_train']\n",
    "mel_test = file['mel_test']\n",
    "y_train = file['y_train']\n",
    "y_test = file['y_test']\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3,3), activation= 'relu', input_shape= mel_train[0].shape, padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(16, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(32, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Conv2D(64, (3,3), activation= 'relu', padding= 'same'))\n",
    "model.add(MaxPooling2D((4,4), padding= 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation= 'relu'))\n",
    "model.add(Dense(10, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= 'Adam', loss= 'categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train Model\n",
    "\n",
    "checkpoint = ModelCheckpoint(os.getcwd()+\"/models/ensemble_model_melspectrogram1_{epoch:03d}.h5\", period= 5)\n",
    "\n",
    "model.fit(mel_train, y_train, epochs= 200, callbacks= [checkpoint], batch_size= 32, verbose= 1)\n",
    "model.save(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")\n",
    "\n",
    "# Load the model\n",
    "model = load_model(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")\n",
    "\n",
    "\n",
    "# Training Accuracy\n",
    "y_pred = model.predict(mel_train)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Train Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Testing Accuracy\n",
    "y_pred = model.predict(mel_test)\n",
    "y_pred = np.argmax(y_pred, axis= -1)\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "print(\"Testing Accuracy\", acc)\n",
    "\n",
    "class_names = ['Experimental', 'Rock', 'Instrumental', 'International', 'Hip-Hop', 'Folk', 'Electronic', 'Pop']\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (8,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/ensemble_mel_conf_mat1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spectrogram model 1\n",
    "spec_file = np.load(os.getcwd()+\"/new_spectrogram_train_test.npz\")\n",
    "\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model1 = load_model(os.getcwd() + \"/models/new_spec_model_spectrogram1.h5\")\n",
    "\n",
    "# Load Spectrogram model 2\n",
    "S_train = spec_file['S_train']\n",
    "S_test = spec_file['S_test']\n",
    "y_train = spec_file['y_train']\n",
    "y_test = spec_file['y_test']\n",
    "\n",
    "model2 = load_model(os.getcwd() + \"/models/new_spec_model_spectrogram2.h5\")\n",
    "\n",
    "# Load MFCC model 1,2 and 3\n",
    "mfcc_file = np.load(os.getcwd()+\"/new_mfcc_train_test.npz\")\n",
    "mfcc_train = mfcc_file['mfcc_train']\n",
    "mfcc_test = mfcc_file['mfcc_test']\n",
    "y_train = mfcc_file['y_train']\n",
    "y_test = mfcc_file['y_test']\n",
    "\n",
    "model3 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc1.h5\")\n",
    "model4 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc2.h5\")\n",
    "model5 = load_model(os.getcwd() + \"/models/new_ensemble_mfcc3.h5\")\n",
    "\n",
    "# Load Mel-spectrogram model\n",
    "file = np.load(os.getcwd()+\"/new_mel_train_test.npz\")\n",
    "mel_train = file['mel_train']\n",
    "mel_test = file['mel_test']\n",
    "y_train = file['y_train']\n",
    "y_test = file['y_test']\n",
    "\n",
    "model6 = load_model(os.getcwd() + \"/models/ensemble_model_melspectrogram1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = np.argmax(y_train, axis= -1)\n",
    "\n",
    "# Spectrogram model 1\n",
    "y_pred1 = model1.predict(S_train)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "# Spectrogram model 2\n",
    "y_pred2 = model2.predict(S_train)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "# MFCC model 1\n",
    "y_pred3 = model3.predict(mfcc_train)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "# MFCC model 2\n",
    "y_pred4 = model4.predict(mfcc_train)\n",
    "y_pred4 = np.argmax(y_pred4, axis= -1)\n",
    "\n",
    "# MFCC model 3\n",
    "y_pred5 = model5.predict(mfcc_train)\n",
    "y_pred5 = np.argmax(y_pred5, axis= -1)\n",
    "\n",
    "# Mel-spectrogram \n",
    "y_pred6 = model6.predict(mel_train)\n",
    "y_pred6 = np.argmax(y_pred6, axis= -1)\n",
    "\n",
    "# Get majority vote\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6]\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "\n",
    "print(\"Training Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "# Test Model\n",
    "y_true = np.argmax(y_test, axis= -1)\n",
    "# Spectrogram model 1\n",
    "y_pred1 = model1.predict(S_test)\n",
    "y_pred1 = np.argmax(y_pred1, axis= -1)\n",
    "\n",
    "# Spectrogram model 2\n",
    "y_pred2 = model2.predict(S_test)\n",
    "y_pred2 = np.argmax(y_pred2, axis= -1)\n",
    "\n",
    "# MFCC model 1\n",
    "y_pred3 = model3.predict(mfcc_test)\n",
    "y_pred3 = np.argmax(y_pred3, axis= -1)\n",
    "\n",
    "# MFCC model 2\n",
    "y_pred4 = model4.predict(mfcc_test)\n",
    "y_pred4 = np.argmax(y_pred4, axis= -1)\n",
    "\n",
    "# MFCC model 3\n",
    "y_pred5 = model5.predict(mfcc_test)\n",
    "y_pred5 = np.argmax(y_pred5, axis= -1)\n",
    "\n",
    "# Mel-Spectrogram \n",
    "y_pred6 = model6.predict(mel_test)\n",
    "y_pred6 = np.argmax(y_pred6, axis= -1)\n",
    "\n",
    "# Get majority vote\n",
    "y_pred = [y_pred1, y_pred2, y_pred3, y_pred4, y_pred5, y_pred6]\n",
    "y_pred = get_majority(y_pred)\n",
    "\n",
    "correct = len(y_pred) - np.count_nonzero(y_pred - y_true)\n",
    "acc = correct/ len(y_pred)\n",
    "acc = np.round(acc, 4) * 100\n",
    "print(\"Testing Accuracy: \", correct, \"/\", len(y_pred), \" = \", acc, \"%\")\n",
    "\n",
    "class_names = ['Experimental', 'Rock', 'Instrumental', 'International', 'Hip-Hop', 'Folk', 'Electronic', 'Pop']\n",
    "conf_mat = confusion_matrix(y_true, y_pred, normalize= 'true')\n",
    "conf_mat = np.round(conf_mat, 2)\n",
    "\n",
    "conf_mat_df = pd.DataFrame(conf_mat, columns= class_names, index= class_names)\n",
    "\n",
    "plt.figure(figsize = (10,7), dpi = 200)\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(conf_mat_df, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.getcwd() + \"/new_ensemble_conf_mat.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
