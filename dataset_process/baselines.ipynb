{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [FMA: A Dataset For Music Analysis](https://github.com/mdeff/fma)\n",
    "\n",
    "MichaÃ«l Defferrard, Kirell Benzi, Pierre Vandergheynst, Xavier Bresson, EPFL LTS2.\n",
    "\n",
    "## Baselines\n",
    "\n",
    "* This notebook evaluates standard classifiers from scikit-learn on the provided features.\n",
    "* Moreover, it evaluates Deep Learning models on both audio and spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import keras\n",
    "# from keras.layers import Activation, Dense, Conv1D, Conv2D, MaxPooling1D, Flatten, Reshape\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "#from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "#from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106574, 52), (106574, 518), (13129, 249))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUDIO_DIR = 'data/fma_small/'\n",
    "\n",
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "features = utils.load('data/fma_metadata/features.csv')\n",
    "echonest = utils.load('data/fma_metadata/echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough Echonest features: (13129, 767)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((25000, 52), (25000, 518))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset = tracks.index[tracks['set', 'subset'] <= 'medium']\n",
    "assert subset.isin(tracks.index).all()\n",
    "assert subset.isin(features.index).all()\n",
    "\n",
    "features_all = features.join(echonest, how='inner').sort_index(axis=1)\n",
    "print('Not enough Echonest features: {}'.format(features_all.shape))\n",
    "\n",
    "tracks = tracks.loc[subset]\n",
    "features_all = features.loc[subset]\n",
    "\n",
    "tracks.shape, features_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19922 training examples, 2505 validation examples, 2573 testing examples\n",
      "Top genres (16): ['Blues', 'Classical', 'Country', 'Easy Listening', 'Electronic', 'Experimental', 'Folk', 'Hip-Hop', 'Instrumental', 'International', 'Jazz', 'Old-Time / Historic', 'Pop', 'Rock', 'Soul-RnB', 'Spoken']\n",
      "All genres (151): [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 30, 31, 32, 33, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 53, 58, 63, 64, 65, 66, 70, 71, 74, 76, 77, 79, 81, 83, 85, 86, 88, 89, 90, 92, 94, 97, 98, 100, 101, 102, 103, 107, 109, 111, 113, 117, 118, 125, 130, 137, 138, 166, 167, 169, 171, 172, 174, 177, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 214, 224, 232, 236, 240, 247, 250, 267, 286, 296, 297, 311, 314, 322, 337, 359, 360, 361, 362, 374, 378, 400, 401, 404, 428, 439, 440, 441, 442, 443, 456, 468, 491, 495, 502, 504, 514, 524, 538, 539, 542, 580, 602, 619, 651, 659, 695, 741, 763, 808, 810, 811, 906, 1032, 1060, 1193, 1235]\n"
     ]
    }
   ],
   "source": [
    "train = tracks.index[tracks['set', 'split'] == 'training']\n",
    "val = tracks.index[tracks['set', 'split'] == 'validation']\n",
    "test = tracks.index[tracks['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n",
    "\n",
    "genres = list(LabelEncoder().fit(tracks['track', 'genre_top']).classes_)\n",
    "#genres = list(tracks['track', 'genre_top'].unique())\n",
    "print('Top genres ({}): {}'.format(len(genres), genres))\n",
    "genres = list(MultiLabelBinarizer().fit(tracks['track', 'genres_all']).classes_)\n",
    "print('All genres ({}): {}'.format(len(genres), genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Multiple classifiers and feature sets\n",
    "\n",
    "Todo:\n",
    "* Cross-validation for hyper-parameters.\n",
    "* Dimensionality reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(tracks, features, columns, multi_label=False, verbose=False):\n",
    "    if not multi_label:\n",
    "        # Assign an integer value to each genre.\n",
    "        enc = LabelEncoder()\n",
    "        labels = tracks['track', 'genre_top']\n",
    "        #y = enc.fit_transform(tracks['track', 'genre_top'])\n",
    "    else:\n",
    "        # Create an indicator matrix.\n",
    "        enc = MultiLabelBinarizer()\n",
    "        labels = tracks['track', 'genres_all']\n",
    "        #labels = tracks['track', 'genres']\n",
    "\n",
    "    # Split in training, validation and testing sets.\n",
    "    y_train = enc.fit_transform(labels[train])\n",
    "    y_val = enc.transform(labels[val])\n",
    "    y_test = enc.transform(labels[test])\n",
    "    X_train = features.loc[train, columns].values\n",
    "    X_val = features.loc[val, columns].values\n",
    "    X_test = features.loc[test, columns].values\n",
    "    \n",
    "    X_train, y_train = shuffle(X_train, y_train, random_state=42)\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance.\n",
    "    scaler = StandardScaler(copy=False)\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_val)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    return y_train, y_val, y_test, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Single genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers_features(classifiers, feature_sets, multi_label=False):\n",
    "    columns = list(classifiers.keys()).insert(0, 'dim')\n",
    "    scores = pd.DataFrame(columns=columns, index=feature_sets.keys())\n",
    "    times = pd.DataFrame(columns=classifiers.keys(), index=feature_sets.keys())\n",
    "    for fset_name, fset in tqdm(feature_sets.items(), desc='features'):\n",
    "        y_train, y_val, y_test, X_train, X_val, X_test = pre_process(tracks, features_all, fset, multi_label)\n",
    "        scores.loc[fset_name, 'dim'] = X_train.shape[1]\n",
    "        for clf_name, clf in classifiers.items():  # tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\n",
    "            t = time.process_time()\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            scores.loc[fset_name, clf_name] = score\n",
    "            times.loc[fset_name, clf_name] = time.process_time() - t\n",
    "    return scores, times\n",
    "\n",
    "def format_scores(scores):\n",
    "    def highlight(s):\n",
    "        is_max = s == max(s[1:])\n",
    "        return ['background-color: yellow' if v else '' for v in is_max]\n",
    "    scores = scores.style.apply(highlight, axis=1)\n",
    "    return scores.format('{:.2%}', subset=pd.IndexSlice[:, scores.columns[1]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7e3c7201dc7484795fd1be6edd4c158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0973a_row0_col3, #T_0973a_row1_col3, #T_0973a_row2_col3, #T_0973a_row3_col3, #T_0973a_row4_col3, #T_0973a_row5_col10, #T_0973a_row6_col10, #T_0973a_row7_col3, #T_0973a_row8_col10, #T_0973a_row9_col3, #T_0973a_row10_col10, #T_0973a_row11_col3, #T_0973a_row12_col3, #T_0973a_row13_col3, #T_0973a_row14_col3, #T_0973a_row15_col3, #T_0973a_row16_col3, #T_0973a_row17_col3 {\n",
       "  background-color: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0973a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0973a_level0_col0\" class=\"col_heading level0 col0\" >dim</th>\n",
       "      <th id=\"T_0973a_level0_col1\" class=\"col_heading level0 col1\" >LR</th>\n",
       "      <th id=\"T_0973a_level0_col2\" class=\"col_heading level0 col2\" >kNN</th>\n",
       "      <th id=\"T_0973a_level0_col3\" class=\"col_heading level0 col3\" >SVCrbf</th>\n",
       "      <th id=\"T_0973a_level0_col4\" class=\"col_heading level0 col4\" >SVCpoly1</th>\n",
       "      <th id=\"T_0973a_level0_col5\" class=\"col_heading level0 col5\" >linSVC1</th>\n",
       "      <th id=\"T_0973a_level0_col6\" class=\"col_heading level0 col6\" >linSVC2</th>\n",
       "      <th id=\"T_0973a_level0_col7\" class=\"col_heading level0 col7\" >DT</th>\n",
       "      <th id=\"T_0973a_level0_col8\" class=\"col_heading level0 col8\" >RF</th>\n",
       "      <th id=\"T_0973a_level0_col9\" class=\"col_heading level0 col9\" >AdaBoost</th>\n",
       "      <th id=\"T_0973a_level0_col10\" class=\"col_heading level0 col10\" >MLP1</th>\n",
       "      <th id=\"T_0973a_level0_col11\" class=\"col_heading level0 col11\" >MLP2</th>\n",
       "      <th id=\"T_0973a_level0_col12\" class=\"col_heading level0 col12\" >NB</th>\n",
       "      <th id=\"T_0973a_level0_col13\" class=\"col_heading level0 col13\" >QDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "      <td id=\"T_0973a_row0_col0\" class=\"data row0 col0\" >84.000000</td>\n",
       "      <td id=\"T_0973a_row0_col1\" class=\"data row0 col1\" >39.33%</td>\n",
       "      <td id=\"T_0973a_row0_col2\" class=\"data row0 col2\" >37.50%</td>\n",
       "      <td id=\"T_0973a_row0_col3\" class=\"data row0 col3\" >42.29%</td>\n",
       "      <td id=\"T_0973a_row0_col4\" class=\"data row0 col4\" >38.63%</td>\n",
       "      <td id=\"T_0973a_row0_col5\" class=\"data row0 col5\" >39.29%</td>\n",
       "      <td id=\"T_0973a_row0_col6\" class=\"data row0 col6\" >39.10%</td>\n",
       "      <td id=\"T_0973a_row0_col7\" class=\"data row0 col7\" >35.72%</td>\n",
       "      <td id=\"T_0973a_row0_col8\" class=\"data row0 col8\" >33.46%</td>\n",
       "      <td id=\"T_0973a_row0_col9\" class=\"data row0 col9\" >30.86%</td>\n",
       "      <td id=\"T_0973a_row0_col10\" class=\"data row0 col10\" >39.41%</td>\n",
       "      <td id=\"T_0973a_row0_col11\" class=\"data row0 col11\" >33.04%</td>\n",
       "      <td id=\"T_0973a_row0_col12\" class=\"data row0 col12\" >9.99%</td>\n",
       "      <td id=\"T_0973a_row0_col13\" class=\"data row0 col13\" >24.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "      <td id=\"T_0973a_row1_col0\" class=\"data row1 col0\" >84.000000</td>\n",
       "      <td id=\"T_0973a_row1_col1\" class=\"data row1 col1\" >40.42%</td>\n",
       "      <td id=\"T_0973a_row1_col2\" class=\"data row1 col2\" >40.03%</td>\n",
       "      <td id=\"T_0973a_row1_col3\" class=\"data row1 col3\" >44.27%</td>\n",
       "      <td id=\"T_0973a_row1_col4\" class=\"data row1 col4\" >39.99%</td>\n",
       "      <td id=\"T_0973a_row1_col5\" class=\"data row1 col5\" >41.39%</td>\n",
       "      <td id=\"T_0973a_row1_col6\" class=\"data row1 col6\" >40.46%</td>\n",
       "      <td id=\"T_0973a_row1_col7\" class=\"data row1 col7\" >35.45%</td>\n",
       "      <td id=\"T_0973a_row1_col8\" class=\"data row1 col8\" >36.81%</td>\n",
       "      <td id=\"T_0973a_row1_col9\" class=\"data row1 col9\" >35.72%</td>\n",
       "      <td id=\"T_0973a_row1_col10\" class=\"data row1 col10\" >42.79%</td>\n",
       "      <td id=\"T_0973a_row1_col11\" class=\"data row1 col11\" >36.46%</td>\n",
       "      <td id=\"T_0973a_row1_col12\" class=\"data row1 col12\" >1.55%</td>\n",
       "      <td id=\"T_0973a_row1_col13\" class=\"data row1 col13\" >3.54%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "      <td id=\"T_0973a_row2_col0\" class=\"data row2 col0\" >84.000000</td>\n",
       "      <td id=\"T_0973a_row2_col1\" class=\"data row2 col1\" >44.00%</td>\n",
       "      <td id=\"T_0973a_row2_col2\" class=\"data row2 col2\" >43.92%</td>\n",
       "      <td id=\"T_0973a_row2_col3\" class=\"data row2 col3\" >48.31%</td>\n",
       "      <td id=\"T_0973a_row2_col4\" class=\"data row2 col4\" >43.65%</td>\n",
       "      <td id=\"T_0973a_row2_col5\" class=\"data row2 col5\" >44.35%</td>\n",
       "      <td id=\"T_0973a_row2_col6\" class=\"data row2 col6\" >43.18%</td>\n",
       "      <td id=\"T_0973a_row2_col7\" class=\"data row2 col7\" >39.88%</td>\n",
       "      <td id=\"T_0973a_row2_col8\" class=\"data row2 col8\" >38.75%</td>\n",
       "      <td id=\"T_0973a_row2_col9\" class=\"data row2 col9\" >35.25%</td>\n",
       "      <td id=\"T_0973a_row2_col10\" class=\"data row2 col10\" >47.38%</td>\n",
       "      <td id=\"T_0973a_row2_col11\" class=\"data row2 col11\" >39.29%</td>\n",
       "      <td id=\"T_0973a_row2_col12\" class=\"data row2 col12\" >4.20%</td>\n",
       "      <td id=\"T_0973a_row2_col13\" class=\"data row2 col13\" >5.95%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "      <td id=\"T_0973a_row3_col0\" class=\"data row3 col0\" >140.000000</td>\n",
       "      <td id=\"T_0973a_row3_col1\" class=\"data row3 col1\" >58.03%</td>\n",
       "      <td id=\"T_0973a_row3_col2\" class=\"data row3 col2\" >54.99%</td>\n",
       "      <td id=\"T_0973a_row3_col3\" class=\"data row3 col3\" >60.98%</td>\n",
       "      <td id=\"T_0973a_row3_col4\" class=\"data row3 col4\" >59.66%</td>\n",
       "      <td id=\"T_0973a_row3_col5\" class=\"data row3 col5\" >59.19%</td>\n",
       "      <td id=\"T_0973a_row3_col6\" class=\"data row3 col6\" >56.51%</td>\n",
       "      <td id=\"T_0973a_row3_col7\" class=\"data row3 col7\" >45.82%</td>\n",
       "      <td id=\"T_0973a_row3_col8\" class=\"data row3 col8\" >45.90%</td>\n",
       "      <td id=\"T_0973a_row3_col9\" class=\"data row3 col9\" >41.31%</td>\n",
       "      <td id=\"T_0973a_row3_col10\" class=\"data row3 col10\" >50.37%</td>\n",
       "      <td id=\"T_0973a_row3_col11\" class=\"data row3 col11\" >52.04%</td>\n",
       "      <td id=\"T_0973a_row3_col12\" class=\"data row3 col12\" >41.86%</td>\n",
       "      <td id=\"T_0973a_row3_col13\" class=\"data row3 col13\" >48.39%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "      <td id=\"T_0973a_row4_col0\" class=\"data row4 col0\" >7.000000</td>\n",
       "      <td id=\"T_0973a_row4_col1\" class=\"data row4 col1\" >36.81%</td>\n",
       "      <td id=\"T_0973a_row4_col2\" class=\"data row4 col2\" >38.52%</td>\n",
       "      <td id=\"T_0973a_row4_col3\" class=\"data row4 col3\" >38.90%</td>\n",
       "      <td id=\"T_0973a_row4_col4\" class=\"data row4 col4\" >37.70%</td>\n",
       "      <td id=\"T_0973a_row4_col5\" class=\"data row4 col5\" >37.54%</td>\n",
       "      <td id=\"T_0973a_row4_col6\" class=\"data row4 col6\" >37.35%</td>\n",
       "      <td id=\"T_0973a_row4_col7\" class=\"data row4 col7\" >38.63%</td>\n",
       "      <td id=\"T_0973a_row4_col8\" class=\"data row4 col8\" >36.96%</td>\n",
       "      <td id=\"T_0973a_row4_col9\" class=\"data row4 col9\" >34.67%</td>\n",
       "      <td id=\"T_0973a_row4_col10\" class=\"data row4 col10\" >38.55%</td>\n",
       "      <td id=\"T_0973a_row4_col11\" class=\"data row4 col11\" >38.40%</td>\n",
       "      <td id=\"T_0973a_row4_col12\" class=\"data row4 col12\" >11.78%</td>\n",
       "      <td id=\"T_0973a_row4_col13\" class=\"data row4 col13\" >15.04%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "      <td id=\"T_0973a_row5_col0\" class=\"data row5 col0\" >7.000000</td>\n",
       "      <td id=\"T_0973a_row5_col1\" class=\"data row5 col1\" >40.61%</td>\n",
       "      <td id=\"T_0973a_row5_col2\" class=\"data row5 col2\" >45.39%</td>\n",
       "      <td id=\"T_0973a_row5_col3\" class=\"data row5 col3\" >44.46%</td>\n",
       "      <td id=\"T_0973a_row5_col4\" class=\"data row5 col4\" >40.38%</td>\n",
       "      <td id=\"T_0973a_row5_col5\" class=\"data row5 col5\" >40.42%</td>\n",
       "      <td id=\"T_0973a_row5_col6\" class=\"data row5 col6\" >40.65%</td>\n",
       "      <td id=\"T_0973a_row5_col7\" class=\"data row5 col7\" >42.91%</td>\n",
       "      <td id=\"T_0973a_row5_col8\" class=\"data row5 col8\" >44.19%</td>\n",
       "      <td id=\"T_0973a_row5_col9\" class=\"data row5 col9\" >37.47%</td>\n",
       "      <td id=\"T_0973a_row5_col10\" class=\"data row5 col10\" >45.47%</td>\n",
       "      <td id=\"T_0973a_row5_col11\" class=\"data row5 col11\" >42.56%</td>\n",
       "      <td id=\"T_0973a_row5_col12\" class=\"data row5 col12\" >36.18%</td>\n",
       "      <td id=\"T_0973a_row5_col13\" class=\"data row5 col13\" >34.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "      <td id=\"T_0973a_row6_col0\" class=\"data row6 col0\" >7.000000</td>\n",
       "      <td id=\"T_0973a_row6_col1\" class=\"data row6 col1\" >42.79%</td>\n",
       "      <td id=\"T_0973a_row6_col2\" class=\"data row6 col2\" >45.36%</td>\n",
       "      <td id=\"T_0973a_row6_col3\" class=\"data row6 col3\" >45.71%</td>\n",
       "      <td id=\"T_0973a_row6_col4\" class=\"data row6 col4\" >42.09%</td>\n",
       "      <td id=\"T_0973a_row6_col5\" class=\"data row6 col5\" >42.09%</td>\n",
       "      <td id=\"T_0973a_row6_col6\" class=\"data row6 col6\" >42.13%</td>\n",
       "      <td id=\"T_0973a_row6_col7\" class=\"data row6 col7\" >42.67%</td>\n",
       "      <td id=\"T_0973a_row6_col8\" class=\"data row6 col8\" >44.27%</td>\n",
       "      <td id=\"T_0973a_row6_col9\" class=\"data row6 col9\" >42.60%</td>\n",
       "      <td id=\"T_0973a_row6_col10\" class=\"data row6 col10\" >46.95%</td>\n",
       "      <td id=\"T_0973a_row6_col11\" class=\"data row6 col11\" >46.68%</td>\n",
       "      <td id=\"T_0973a_row6_col12\" class=\"data row6 col12\" >33.31%</td>\n",
       "      <td id=\"T_0973a_row6_col13\" class=\"data row6 col13\" >36.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "      <td id=\"T_0973a_row7_col0\" class=\"data row7 col0\" >49.000000</td>\n",
       "      <td id=\"T_0973a_row7_col1\" class=\"data row7 col1\" >51.61%</td>\n",
       "      <td id=\"T_0973a_row7_col2\" class=\"data row7 col2\" >49.55%</td>\n",
       "      <td id=\"T_0973a_row7_col3\" class=\"data row7 col3\" >54.45%</td>\n",
       "      <td id=\"T_0973a_row7_col4\" class=\"data row7 col4\" >49.59%</td>\n",
       "      <td id=\"T_0973a_row7_col5\" class=\"data row7 col5\" >51.81%</td>\n",
       "      <td id=\"T_0973a_row7_col6\" class=\"data row7 col6\" >48.97%</td>\n",
       "      <td id=\"T_0973a_row7_col7\" class=\"data row7 col7\" >43.53%</td>\n",
       "      <td id=\"T_0973a_row7_col8\" class=\"data row7 col8\" >42.91%</td>\n",
       "      <td id=\"T_0973a_row7_col9\" class=\"data row7 col9\" >39.53%</td>\n",
       "      <td id=\"T_0973a_row7_col10\" class=\"data row7 col10\" >52.00%</td>\n",
       "      <td id=\"T_0973a_row7_col11\" class=\"data row7 col11\" >44.15%</td>\n",
       "      <td id=\"T_0973a_row7_col12\" class=\"data row7 col12\" >39.41%</td>\n",
       "      <td id=\"T_0973a_row7_col13\" class=\"data row7 col13\" >41.78%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "      <td id=\"T_0973a_row8_col0\" class=\"data row8 col0\" >7.000000</td>\n",
       "      <td id=\"T_0973a_row8_col1\" class=\"data row8 col1\" >41.86%</td>\n",
       "      <td id=\"T_0973a_row8_col2\" class=\"data row8 col2\" >46.25%</td>\n",
       "      <td id=\"T_0973a_row8_col3\" class=\"data row8 col3\" >47.53%</td>\n",
       "      <td id=\"T_0973a_row8_col4\" class=\"data row8 col4\" >41.43%</td>\n",
       "      <td id=\"T_0973a_row8_col5\" class=\"data row8 col5\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row8_col6\" class=\"data row8 col6\" >41.51%</td>\n",
       "      <td id=\"T_0973a_row8_col7\" class=\"data row8 col7\" >45.36%</td>\n",
       "      <td id=\"T_0973a_row8_col8\" class=\"data row8 col8\" >45.55%</td>\n",
       "      <td id=\"T_0973a_row8_col9\" class=\"data row8 col9\" >41.66%</td>\n",
       "      <td id=\"T_0973a_row8_col10\" class=\"data row8 col10\" >47.92%</td>\n",
       "      <td id=\"T_0973a_row8_col11\" class=\"data row8 col11\" >46.95%</td>\n",
       "      <td id=\"T_0973a_row8_col12\" class=\"data row8 col12\" >28.49%</td>\n",
       "      <td id=\"T_0973a_row8_col13\" class=\"data row8 col13\" >28.53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "      <td id=\"T_0973a_row9_col0\" class=\"data row9 col0\" >42.000000</td>\n",
       "      <td id=\"T_0973a_row9_col1\" class=\"data row9 col1\" >40.11%</td>\n",
       "      <td id=\"T_0973a_row9_col2\" class=\"data row9 col2\" >37.31%</td>\n",
       "      <td id=\"T_0973a_row9_col3\" class=\"data row9 col3\" >42.25%</td>\n",
       "      <td id=\"T_0973a_row9_col4\" class=\"data row9 col4\" >40.23%</td>\n",
       "      <td id=\"T_0973a_row9_col5\" class=\"data row9 col5\" >40.19%</td>\n",
       "      <td id=\"T_0973a_row9_col6\" class=\"data row9 col6\" >39.53%</td>\n",
       "      <td id=\"T_0973a_row9_col7\" class=\"data row9 col7\" >35.91%</td>\n",
       "      <td id=\"T_0973a_row9_col8\" class=\"data row9 col8\" >36.03%</td>\n",
       "      <td id=\"T_0973a_row9_col9\" class=\"data row9 col9\" >34.16%</td>\n",
       "      <td id=\"T_0973a_row9_col10\" class=\"data row9 col10\" >39.95%</td>\n",
       "      <td id=\"T_0973a_row9_col11\" class=\"data row9 col11\" >31.52%</td>\n",
       "      <td id=\"T_0973a_row9_col12\" class=\"data row9 col12\" >22.31%</td>\n",
       "      <td id=\"T_0973a_row9_col13\" class=\"data row9 col13\" >23.05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "      <td id=\"T_0973a_row10_col0\" class=\"data row10 col0\" >7.000000</td>\n",
       "      <td id=\"T_0973a_row10_col1\" class=\"data row10 col1\" >43.53%</td>\n",
       "      <td id=\"T_0973a_row10_col2\" class=\"data row10 col2\" >44.73%</td>\n",
       "      <td id=\"T_0973a_row10_col3\" class=\"data row10 col3\" >45.43%</td>\n",
       "      <td id=\"T_0973a_row10_col4\" class=\"data row10 col4\" >42.95%</td>\n",
       "      <td id=\"T_0973a_row10_col5\" class=\"data row10 col5\" >42.67%</td>\n",
       "      <td id=\"T_0973a_row10_col6\" class=\"data row10 col6\" >42.09%</td>\n",
       "      <td id=\"T_0973a_row10_col7\" class=\"data row10 col7\" >43.61%</td>\n",
       "      <td id=\"T_0973a_row10_col8\" class=\"data row10 col8\" >44.07%</td>\n",
       "      <td id=\"T_0973a_row10_col9\" class=\"data row10 col9\" >40.89%</td>\n",
       "      <td id=\"T_0973a_row10_col10\" class=\"data row10 col10\" >46.09%</td>\n",
       "      <td id=\"T_0973a_row10_col11\" class=\"data row10 col11\" >45.98%</td>\n",
       "      <td id=\"T_0973a_row10_col12\" class=\"data row10 col12\" >30.39%</td>\n",
       "      <td id=\"T_0973a_row10_col13\" class=\"data row10 col13\" >32.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "      <td id=\"T_0973a_row11_col0\" class=\"data row11 col0\" >189.000000</td>\n",
       "      <td id=\"T_0973a_row11_col1\" class=\"data row11 col1\" >59.77%</td>\n",
       "      <td id=\"T_0973a_row11_col2\" class=\"data row11 col2\" >55.31%</td>\n",
       "      <td id=\"T_0973a_row11_col3\" class=\"data row11 col3\" >63.04%</td>\n",
       "      <td id=\"T_0973a_row11_col4\" class=\"data row11 col4\" >61.02%</td>\n",
       "      <td id=\"T_0973a_row11_col5\" class=\"data row11 col5\" >59.58%</td>\n",
       "      <td id=\"T_0973a_row11_col6\" class=\"data row11 col6\" >58.57%</td>\n",
       "      <td id=\"T_0973a_row11_col7\" class=\"data row11 col7\" >47.61%</td>\n",
       "      <td id=\"T_0973a_row11_col8\" class=\"data row11 col8\" >45.39%</td>\n",
       "      <td id=\"T_0973a_row11_col9\" class=\"data row11 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row11_col10\" class=\"data row11 col10\" >52.16%</td>\n",
       "      <td id=\"T_0973a_row11_col11\" class=\"data row11 col11\" >55.81%</td>\n",
       "      <td id=\"T_0973a_row11_col12\" class=\"data row11 col12\" >44.03%</td>\n",
       "      <td id=\"T_0973a_row11_col13\" class=\"data row11 col13\" >51.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "      <td id=\"T_0973a_row12_col0\" class=\"data row12 col0\" >273.000000</td>\n",
       "      <td id=\"T_0973a_row12_col1\" class=\"data row12 col1\" >60.36%</td>\n",
       "      <td id=\"T_0973a_row12_col2\" class=\"data row12 col2\" >53.13%</td>\n",
       "      <td id=\"T_0973a_row12_col3\" class=\"data row12 col3\" >62.92%</td>\n",
       "      <td id=\"T_0973a_row12_col4\" class=\"data row12 col4\" >61.48%</td>\n",
       "      <td id=\"T_0973a_row12_col5\" class=\"data row12 col5\" >59.11%</td>\n",
       "      <td id=\"T_0973a_row12_col6\" class=\"data row12 col6\" >59.15%</td>\n",
       "      <td id=\"T_0973a_row12_col7\" class=\"data row12 col7\" >47.57%</td>\n",
       "      <td id=\"T_0973a_row12_col8\" class=\"data row12 col8\" >45.90%</td>\n",
       "      <td id=\"T_0973a_row12_col9\" class=\"data row12 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row12_col10\" class=\"data row12 col10\" >54.33%</td>\n",
       "      <td id=\"T_0973a_row12_col11\" class=\"data row12 col11\" >56.63%</td>\n",
       "      <td id=\"T_0973a_row12_col12\" class=\"data row12 col12\" >39.02%</td>\n",
       "      <td id=\"T_0973a_row12_col13\" class=\"data row12 col13\" >51.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "      <td id=\"T_0973a_row13_col0\" class=\"data row13 col0\" >196.000000</td>\n",
       "      <td id=\"T_0973a_row13_col1\" class=\"data row13 col1\" >60.47%</td>\n",
       "      <td id=\"T_0973a_row13_col2\" class=\"data row13 col2\" >55.23%</td>\n",
       "      <td id=\"T_0973a_row13_col3\" class=\"data row13 col3\" >63.39%</td>\n",
       "      <td id=\"T_0973a_row13_col4\" class=\"data row13 col4\" >61.48%</td>\n",
       "      <td id=\"T_0973a_row13_col5\" class=\"data row13 col5\" >60.28%</td>\n",
       "      <td id=\"T_0973a_row13_col6\" class=\"data row13 col6\" >59.19%</td>\n",
       "      <td id=\"T_0973a_row13_col7\" class=\"data row13 col7\" >47.57%</td>\n",
       "      <td id=\"T_0973a_row13_col8\" class=\"data row13 col8\" >44.97%</td>\n",
       "      <td id=\"T_0973a_row13_col9\" class=\"data row13 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row13_col10\" class=\"data row13 col10\" >53.52%</td>\n",
       "      <td id=\"T_0973a_row13_col11\" class=\"data row13 col11\" >55.73%</td>\n",
       "      <td id=\"T_0973a_row13_col12\" class=\"data row13 col12\" >43.76%</td>\n",
       "      <td id=\"T_0973a_row13_col13\" class=\"data row13 col13\" >51.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "      <td id=\"T_0973a_row14_col0\" class=\"data row14 col0\" >280.000000</td>\n",
       "      <td id=\"T_0973a_row14_col1\" class=\"data row14 col1\" >60.09%</td>\n",
       "      <td id=\"T_0973a_row14_col2\" class=\"data row14 col2\" >53.01%</td>\n",
       "      <td id=\"T_0973a_row14_col3\" class=\"data row14 col3\" >63.08%</td>\n",
       "      <td id=\"T_0973a_row14_col4\" class=\"data row14 col4\" >61.29%</td>\n",
       "      <td id=\"T_0973a_row14_col5\" class=\"data row14 col5\" >60.12%</td>\n",
       "      <td id=\"T_0973a_row14_col6\" class=\"data row14 col6\" >59.39%</td>\n",
       "      <td id=\"T_0973a_row14_col7\" class=\"data row14 col7\" >47.57%</td>\n",
       "      <td id=\"T_0973a_row14_col8\" class=\"data row14 col8\" >44.27%</td>\n",
       "      <td id=\"T_0973a_row14_col9\" class=\"data row14 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row14_col10\" class=\"data row14 col10\" >55.11%</td>\n",
       "      <td id=\"T_0973a_row14_col11\" class=\"data row14 col11\" >57.91%</td>\n",
       "      <td id=\"T_0973a_row14_col12\" class=\"data row14 col12\" >38.87%</td>\n",
       "      <td id=\"T_0973a_row14_col13\" class=\"data row14 col13\" >51.34%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_0973a_row15_col0\" class=\"data row15 col0\" >322.000000</td>\n",
       "      <td id=\"T_0973a_row15_col1\" class=\"data row15 col1\" >60.86%</td>\n",
       "      <td id=\"T_0973a_row15_col2\" class=\"data row15 col2\" >52.62%</td>\n",
       "      <td id=\"T_0973a_row15_col3\" class=\"data row15 col3\" >63.12%</td>\n",
       "      <td id=\"T_0973a_row15_col4\" class=\"data row15 col4\" >62.50%</td>\n",
       "      <td id=\"T_0973a_row15_col5\" class=\"data row15 col5\" >60.20%</td>\n",
       "      <td id=\"T_0973a_row15_col6\" class=\"data row15 col6\" >59.58%</td>\n",
       "      <td id=\"T_0973a_row15_col7\" class=\"data row15 col7\" >47.57%</td>\n",
       "      <td id=\"T_0973a_row15_col8\" class=\"data row15 col8\" >43.14%</td>\n",
       "      <td id=\"T_0973a_row15_col9\" class=\"data row15 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row15_col10\" class=\"data row15 col10\" >56.12%</td>\n",
       "      <td id=\"T_0973a_row15_col11\" class=\"data row15 col11\" >58.53%</td>\n",
       "      <td id=\"T_0973a_row15_col12\" class=\"data row15 col12\" >39.06%</td>\n",
       "      <td id=\"T_0973a_row15_col13\" class=\"data row15 col13\" >50.72%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_0973a_row16_col0\" class=\"data row16 col0\" >287.000000</td>\n",
       "      <td id=\"T_0973a_row16_col1\" class=\"data row16 col1\" >60.32%</td>\n",
       "      <td id=\"T_0973a_row16_col2\" class=\"data row16 col2\" >53.01%</td>\n",
       "      <td id=\"T_0973a_row16_col3\" class=\"data row16 col3\" >62.81%</td>\n",
       "      <td id=\"T_0973a_row16_col4\" class=\"data row16 col4\" >61.48%</td>\n",
       "      <td id=\"T_0973a_row16_col5\" class=\"data row16 col5\" >59.77%</td>\n",
       "      <td id=\"T_0973a_row16_col6\" class=\"data row16 col6\" >59.77%</td>\n",
       "      <td id=\"T_0973a_row16_col7\" class=\"data row16 col7\" >47.69%</td>\n",
       "      <td id=\"T_0973a_row16_col8\" class=\"data row16 col8\" >44.23%</td>\n",
       "      <td id=\"T_0973a_row16_col9\" class=\"data row16 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row16_col10\" class=\"data row16 col10\" >54.10%</td>\n",
       "      <td id=\"T_0973a_row16_col11\" class=\"data row16 col11\" >59.23%</td>\n",
       "      <td id=\"T_0973a_row16_col12\" class=\"data row16 col12\" >38.90%</td>\n",
       "      <td id=\"T_0973a_row16_col13\" class=\"data row16 col13\" >51.42%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0973a_level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "      <td id=\"T_0973a_row17_col0\" class=\"data row17 col0\" >518.000000</td>\n",
       "      <td id=\"T_0973a_row17_col1\" class=\"data row17 col1\" >60.71%</td>\n",
       "      <td id=\"T_0973a_row17_col2\" class=\"data row17 col2\" >51.77%</td>\n",
       "      <td id=\"T_0973a_row17_col3\" class=\"data row17 col3\" >62.88%</td>\n",
       "      <td id=\"T_0973a_row17_col4\" class=\"data row17 col4\" >61.95%</td>\n",
       "      <td id=\"T_0973a_row17_col5\" class=\"data row17 col5\" >59.08%</td>\n",
       "      <td id=\"T_0973a_row17_col6\" class=\"data row17 col6\" >59.54%</td>\n",
       "      <td id=\"T_0973a_row17_col7\" class=\"data row17 col7\" >47.30%</td>\n",
       "      <td id=\"T_0973a_row17_col8\" class=\"data row17 col8\" >43.84%</td>\n",
       "      <td id=\"T_0973a_row17_col9\" class=\"data row17 col9\" >41.62%</td>\n",
       "      <td id=\"T_0973a_row17_col10\" class=\"data row17 col10\" >56.70%</td>\n",
       "      <td id=\"T_0973a_row17_col11\" class=\"data row17 col11\" >58.53%</td>\n",
       "      <td id=\"T_0973a_row17_col12\" class=\"data row17 col12\" >9.91%</td>\n",
       "      <td id=\"T_0973a_row17_col13\" class=\"data row17 col13\" >19.47%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1eef4436150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d3338\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d3338_level0_col0\" class=\"col_heading level0 col0\" >LR</th>\n",
       "      <th id=\"T_d3338_level0_col1\" class=\"col_heading level0 col1\" >kNN</th>\n",
       "      <th id=\"T_d3338_level0_col2\" class=\"col_heading level0 col2\" >SVCrbf</th>\n",
       "      <th id=\"T_d3338_level0_col3\" class=\"col_heading level0 col3\" >SVCpoly1</th>\n",
       "      <th id=\"T_d3338_level0_col4\" class=\"col_heading level0 col4\" >linSVC1</th>\n",
       "      <th id=\"T_d3338_level0_col5\" class=\"col_heading level0 col5\" >linSVC2</th>\n",
       "      <th id=\"T_d3338_level0_col6\" class=\"col_heading level0 col6\" >DT</th>\n",
       "      <th id=\"T_d3338_level0_col7\" class=\"col_heading level0 col7\" >RF</th>\n",
       "      <th id=\"T_d3338_level0_col8\" class=\"col_heading level0 col8\" >AdaBoost</th>\n",
       "      <th id=\"T_d3338_level0_col9\" class=\"col_heading level0 col9\" >MLP1</th>\n",
       "      <th id=\"T_d3338_level0_col10\" class=\"col_heading level0 col10\" >MLP2</th>\n",
       "      <th id=\"T_d3338_level0_col11\" class=\"col_heading level0 col11\" >NB</th>\n",
       "      <th id=\"T_d3338_level0_col12\" class=\"col_heading level0 col12\" >QDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row0\" class=\"row_heading level0 row0\" >chroma_cens</th>\n",
       "      <td id=\"T_d3338_row0_col0\" class=\"data row0 col0\" >17.2656</td>\n",
       "      <td id=\"T_d3338_row0_col1\" class=\"data row0 col1\" >6.8906</td>\n",
       "      <td id=\"T_d3338_row0_col2\" class=\"data row0 col2\" >43.8281</td>\n",
       "      <td id=\"T_d3338_row0_col3\" class=\"data row0 col3\" >32.3125</td>\n",
       "      <td id=\"T_d3338_row0_col4\" class=\"data row0 col4\" >140.2344</td>\n",
       "      <td id=\"T_d3338_row0_col5\" class=\"data row0 col5\" >99.7500</td>\n",
       "      <td id=\"T_d3338_row0_col6\" class=\"data row0 col6\" >1.7344</td>\n",
       "      <td id=\"T_d3338_row0_col7\" class=\"data row0 col7\" >0.1562</td>\n",
       "      <td id=\"T_d3338_row0_col8\" class=\"data row0 col8\" >3.7344</td>\n",
       "      <td id=\"T_d3338_row0_col9\" class=\"data row0 col9\" >458.1250</td>\n",
       "      <td id=\"T_d3338_row0_col10\" class=\"data row0 col10\" >464.3594</td>\n",
       "      <td id=\"T_d3338_row0_col11\" class=\"data row0 col11\" >0.0625</td>\n",
       "      <td id=\"T_d3338_row0_col12\" class=\"data row0 col12\" >1.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row1\" class=\"row_heading level0 row1\" >chroma_cqt</th>\n",
       "      <td id=\"T_d3338_row1_col0\" class=\"data row1 col0\" >16.6406</td>\n",
       "      <td id=\"T_d3338_row1_col1\" class=\"data row1 col1\" >6.2031</td>\n",
       "      <td id=\"T_d3338_row1_col2\" class=\"data row1 col2\" >39.2656</td>\n",
       "      <td id=\"T_d3338_row1_col3\" class=\"data row1 col3\" >29.8906</td>\n",
       "      <td id=\"T_d3338_row1_col4\" class=\"data row1 col4\" >163.1719</td>\n",
       "      <td id=\"T_d3338_row1_col5\" class=\"data row1 col5\" >76.4531</td>\n",
       "      <td id=\"T_d3338_row1_col6\" class=\"data row1 col6\" >1.2812</td>\n",
       "      <td id=\"T_d3338_row1_col7\" class=\"data row1 col7\" >0.1719</td>\n",
       "      <td id=\"T_d3338_row1_col8\" class=\"data row1 col8\" >3.4219</td>\n",
       "      <td id=\"T_d3338_row1_col9\" class=\"data row1 col9\" >176.1719</td>\n",
       "      <td id=\"T_d3338_row1_col10\" class=\"data row1 col10\" >442.7969</td>\n",
       "      <td id=\"T_d3338_row1_col11\" class=\"data row1 col11\" >0.0469</td>\n",
       "      <td id=\"T_d3338_row1_col12\" class=\"data row1 col12\" >1.3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row2\" class=\"row_heading level0 row2\" >chroma_stft</th>\n",
       "      <td id=\"T_d3338_row2_col0\" class=\"data row2 col0\" >15.8438</td>\n",
       "      <td id=\"T_d3338_row2_col1\" class=\"data row2 col1\" >7.2188</td>\n",
       "      <td id=\"T_d3338_row2_col2\" class=\"data row2 col2\" >30.7344</td>\n",
       "      <td id=\"T_d3338_row2_col3\" class=\"data row2 col3\" >29.9531</td>\n",
       "      <td id=\"T_d3338_row2_col4\" class=\"data row2 col4\" >109.5000</td>\n",
       "      <td id=\"T_d3338_row2_col5\" class=\"data row2 col5\" >74.9062</td>\n",
       "      <td id=\"T_d3338_row2_col6\" class=\"data row2 col6\" >1.3281</td>\n",
       "      <td id=\"T_d3338_row2_col7\" class=\"data row2 col7\" >0.1562</td>\n",
       "      <td id=\"T_d3338_row2_col8\" class=\"data row2 col8\" >3.3281</td>\n",
       "      <td id=\"T_d3338_row2_col9\" class=\"data row2 col9\" >258.6250</td>\n",
       "      <td id=\"T_d3338_row2_col10\" class=\"data row2 col10\" >395.5625</td>\n",
       "      <td id=\"T_d3338_row2_col11\" class=\"data row2 col11\" >0.0312</td>\n",
       "      <td id=\"T_d3338_row2_col12\" class=\"data row2 col12\" >0.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row3\" class=\"row_heading level0 row3\" >mfcc</th>\n",
       "      <td id=\"T_d3338_row3_col0\" class=\"data row3 col0\" >22.7500</td>\n",
       "      <td id=\"T_d3338_row3_col1\" class=\"data row3 col1\" >5.8594</td>\n",
       "      <td id=\"T_d3338_row3_col2\" class=\"data row3 col2\" >39.4375</td>\n",
       "      <td id=\"T_d3338_row3_col3\" class=\"data row3 col3\" >30.1719</td>\n",
       "      <td id=\"T_d3338_row3_col4\" class=\"data row3 col4\" >103.9531</td>\n",
       "      <td id=\"T_d3338_row3_col5\" class=\"data row3 col5\" >75.9219</td>\n",
       "      <td id=\"T_d3338_row3_col6\" class=\"data row3 col6\" >2.6406</td>\n",
       "      <td id=\"T_d3338_row3_col7\" class=\"data row3 col7\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row3_col8\" class=\"data row3 col8\" >6.6875</td>\n",
       "      <td id=\"T_d3338_row3_col9\" class=\"data row3 col9\" >730.0312</td>\n",
       "      <td id=\"T_d3338_row3_col10\" class=\"data row3 col10\" >312.4688</td>\n",
       "      <td id=\"T_d3338_row3_col11\" class=\"data row3 col11\" >0.0781</td>\n",
       "      <td id=\"T_d3338_row3_col12\" class=\"data row3 col12\" >3.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row4\" class=\"row_heading level0 row4\" >rmse</th>\n",
       "      <td id=\"T_d3338_row4_col0\" class=\"data row4 col0\" >4.7031</td>\n",
       "      <td id=\"T_d3338_row4_col1\" class=\"data row4 col1\" >0.5938</td>\n",
       "      <td id=\"T_d3338_row4_col2\" class=\"data row4 col2\" >20.6094</td>\n",
       "      <td id=\"T_d3338_row4_col3\" class=\"data row4 col3\" >11.2344</td>\n",
       "      <td id=\"T_d3338_row4_col4\" class=\"data row4 col4\" >13.2812</td>\n",
       "      <td id=\"T_d3338_row4_col5\" class=\"data row4 col5\" >9.1250</td>\n",
       "      <td id=\"T_d3338_row4_col6\" class=\"data row4 col6\" >0.1250</td>\n",
       "      <td id=\"T_d3338_row4_col7\" class=\"data row4 col7\" >0.1719</td>\n",
       "      <td id=\"T_d3338_row4_col8\" class=\"data row4 col8\" >0.5312</td>\n",
       "      <td id=\"T_d3338_row4_col9\" class=\"data row4 col9\" >81.3750</td>\n",
       "      <td id=\"T_d3338_row4_col10\" class=\"data row4 col10\" >296.6875</td>\n",
       "      <td id=\"T_d3338_row4_col11\" class=\"data row4 col11\" >0.0000</td>\n",
       "      <td id=\"T_d3338_row4_col12\" class=\"data row4 col12\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row5\" class=\"row_heading level0 row5\" >spectral_bandwidth</th>\n",
       "      <td id=\"T_d3338_row5_col0\" class=\"data row5 col0\" >3.6094</td>\n",
       "      <td id=\"T_d3338_row5_col1\" class=\"data row5 col1\" >0.4219</td>\n",
       "      <td id=\"T_d3338_row5_col2\" class=\"data row5 col2\" >25.1094</td>\n",
       "      <td id=\"T_d3338_row5_col3\" class=\"data row5 col3\" >12.2188</td>\n",
       "      <td id=\"T_d3338_row5_col4\" class=\"data row5 col4\" >17.1250</td>\n",
       "      <td id=\"T_d3338_row5_col5\" class=\"data row5 col5\" >9.7188</td>\n",
       "      <td id=\"T_d3338_row5_col6\" class=\"data row5 col6\" >0.1406</td>\n",
       "      <td id=\"T_d3338_row5_col7\" class=\"data row5 col7\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row5_col8\" class=\"data row5 col8\" >0.5625</td>\n",
       "      <td id=\"T_d3338_row5_col9\" class=\"data row5 col9\" >151.5156</td>\n",
       "      <td id=\"T_d3338_row5_col10\" class=\"data row5 col10\" >510.0469</td>\n",
       "      <td id=\"T_d3338_row5_col11\" class=\"data row5 col11\" >0.0156</td>\n",
       "      <td id=\"T_d3338_row5_col12\" class=\"data row5 col12\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row6\" class=\"row_heading level0 row6\" >spectral_centroid</th>\n",
       "      <td id=\"T_d3338_row6_col0\" class=\"data row6 col0\" >3.3750</td>\n",
       "      <td id=\"T_d3338_row6_col1\" class=\"data row6 col1\" >0.5625</td>\n",
       "      <td id=\"T_d3338_row6_col2\" class=\"data row6 col2\" >18.5312</td>\n",
       "      <td id=\"T_d3338_row6_col3\" class=\"data row6 col3\" >12.4688</td>\n",
       "      <td id=\"T_d3338_row6_col4\" class=\"data row6 col4\" >20.7969</td>\n",
       "      <td id=\"T_d3338_row6_col5\" class=\"data row6 col5\" >10.5469</td>\n",
       "      <td id=\"T_d3338_row6_col6\" class=\"data row6 col6\" >0.1250</td>\n",
       "      <td id=\"T_d3338_row6_col7\" class=\"data row6 col7\" >0.1719</td>\n",
       "      <td id=\"T_d3338_row6_col8\" class=\"data row6 col8\" >0.5469</td>\n",
       "      <td id=\"T_d3338_row6_col9\" class=\"data row6 col9\" >126.4062</td>\n",
       "      <td id=\"T_d3338_row6_col10\" class=\"data row6 col10\" >455.2500</td>\n",
       "      <td id=\"T_d3338_row6_col11\" class=\"data row6 col11\" >0.0000</td>\n",
       "      <td id=\"T_d3338_row6_col12\" class=\"data row6 col12\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row7\" class=\"row_heading level0 row7\" >spectral_contrast</th>\n",
       "      <td id=\"T_d3338_row7_col0\" class=\"data row7 col0\" >13.4531</td>\n",
       "      <td id=\"T_d3338_row7_col1\" class=\"data row7 col1\" >5.2656</td>\n",
       "      <td id=\"T_d3338_row7_col2\" class=\"data row7 col2\" >35.6250</td>\n",
       "      <td id=\"T_d3338_row7_col3\" class=\"data row7 col3\" >21.9531</td>\n",
       "      <td id=\"T_d3338_row7_col4\" class=\"data row7 col4\" >54.5781</td>\n",
       "      <td id=\"T_d3338_row7_col5\" class=\"data row7 col5\" >47.5625</td>\n",
       "      <td id=\"T_d3338_row7_col6\" class=\"data row7 col6\" >3.8906</td>\n",
       "      <td id=\"T_d3338_row7_col7\" class=\"data row7 col7\" >0.7031</td>\n",
       "      <td id=\"T_d3338_row7_col8\" class=\"data row7 col8\" >7.6094</td>\n",
       "      <td id=\"T_d3338_row7_col9\" class=\"data row7 col9\" >399.0469</td>\n",
       "      <td id=\"T_d3338_row7_col10\" class=\"data row7 col10\" >776.9531</td>\n",
       "      <td id=\"T_d3338_row7_col11\" class=\"data row7 col11\" >0.0312</td>\n",
       "      <td id=\"T_d3338_row7_col12\" class=\"data row7 col12\" >0.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row8\" class=\"row_heading level0 row8\" >spectral_rolloff</th>\n",
       "      <td id=\"T_d3338_row8_col0\" class=\"data row8 col0\" >2.2656</td>\n",
       "      <td id=\"T_d3338_row8_col1\" class=\"data row8 col1\" >0.3750</td>\n",
       "      <td id=\"T_d3338_row8_col2\" class=\"data row8 col2\" >18.5625</td>\n",
       "      <td id=\"T_d3338_row8_col3\" class=\"data row8 col3\" >19.3906</td>\n",
       "      <td id=\"T_d3338_row8_col4\" class=\"data row8 col4\" >17.0781</td>\n",
       "      <td id=\"T_d3338_row8_col5\" class=\"data row8 col5\" >9.8750</td>\n",
       "      <td id=\"T_d3338_row8_col6\" class=\"data row8 col6\" >0.0938</td>\n",
       "      <td id=\"T_d3338_row8_col7\" class=\"data row8 col7\" >0.1406</td>\n",
       "      <td id=\"T_d3338_row8_col8\" class=\"data row8 col8\" >0.7500</td>\n",
       "      <td id=\"T_d3338_row8_col9\" class=\"data row8 col9\" >127.9219</td>\n",
       "      <td id=\"T_d3338_row8_col10\" class=\"data row8 col10\" >422.3750</td>\n",
       "      <td id=\"T_d3338_row8_col11\" class=\"data row8 col11\" >0.0000</td>\n",
       "      <td id=\"T_d3338_row8_col12\" class=\"data row8 col12\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row9\" class=\"row_heading level0 row9\" >tonnetz</th>\n",
       "      <td id=\"T_d3338_row9_col0\" class=\"data row9 col0\" >12.8594</td>\n",
       "      <td id=\"T_d3338_row9_col1\" class=\"data row9 col1\" >7.3281</td>\n",
       "      <td id=\"T_d3338_row9_col2\" class=\"data row9 col2\" >33.5156</td>\n",
       "      <td id=\"T_d3338_row9_col3\" class=\"data row9 col3\" >19.7500</td>\n",
       "      <td id=\"T_d3338_row9_col4\" class=\"data row9 col4\" >51.3750</td>\n",
       "      <td id=\"T_d3338_row9_col5\" class=\"data row9 col5\" >43.1719</td>\n",
       "      <td id=\"T_d3338_row9_col6\" class=\"data row9 col6\" >1.0312</td>\n",
       "      <td id=\"T_d3338_row9_col7\" class=\"data row9 col7\" >0.1719</td>\n",
       "      <td id=\"T_d3338_row9_col8\" class=\"data row9 col8\" >2.6094</td>\n",
       "      <td id=\"T_d3338_row9_col9\" class=\"data row9 col9\" >285.1094</td>\n",
       "      <td id=\"T_d3338_row9_col10\" class=\"data row9 col10\" >416.2344</td>\n",
       "      <td id=\"T_d3338_row9_col11\" class=\"data row9 col11\" >0.0312</td>\n",
       "      <td id=\"T_d3338_row9_col12\" class=\"data row9 col12\" >0.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row10\" class=\"row_heading level0 row10\" >zcr</th>\n",
       "      <td id=\"T_d3338_row10_col0\" class=\"data row10 col0\" >3.1875</td>\n",
       "      <td id=\"T_d3338_row10_col1\" class=\"data row10 col1\" >0.3594</td>\n",
       "      <td id=\"T_d3338_row10_col2\" class=\"data row10 col2\" >18.3438</td>\n",
       "      <td id=\"T_d3338_row10_col3\" class=\"data row10 col3\" >11.4531</td>\n",
       "      <td id=\"T_d3338_row10_col4\" class=\"data row10 col4\" >17.4062</td>\n",
       "      <td id=\"T_d3338_row10_col5\" class=\"data row10 col5\" >14.1562</td>\n",
       "      <td id=\"T_d3338_row10_col6\" class=\"data row10 col6\" >0.0938</td>\n",
       "      <td id=\"T_d3338_row10_col7\" class=\"data row10 col7\" >0.1406</td>\n",
       "      <td id=\"T_d3338_row10_col8\" class=\"data row10 col8\" >0.4531</td>\n",
       "      <td id=\"T_d3338_row10_col9\" class=\"data row10 col9\" >140.8750</td>\n",
       "      <td id=\"T_d3338_row10_col10\" class=\"data row10 col10\" >403.0469</td>\n",
       "      <td id=\"T_d3338_row10_col11\" class=\"data row10 col11\" >0.0000</td>\n",
       "      <td id=\"T_d3338_row10_col12\" class=\"data row10 col12\" >0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row11\" class=\"row_heading level0 row11\" >mfcc/contrast</th>\n",
       "      <td id=\"T_d3338_row11_col0\" class=\"data row11 col0\" >26.8125</td>\n",
       "      <td id=\"T_d3338_row11_col1\" class=\"data row11 col1\" >6.7969</td>\n",
       "      <td id=\"T_d3338_row11_col2\" class=\"data row11 col2\" >64.3438</td>\n",
       "      <td id=\"T_d3338_row11_col3\" class=\"data row11 col3\" >57.5000</td>\n",
       "      <td id=\"T_d3338_row11_col4\" class=\"data row11 col4\" >173.3750</td>\n",
       "      <td id=\"T_d3338_row11_col5\" class=\"data row11 col5\" >102.4531</td>\n",
       "      <td id=\"T_d3338_row11_col6\" class=\"data row11 col6\" >3.5781</td>\n",
       "      <td id=\"T_d3338_row11_col7\" class=\"data row11 col7\" >0.1719</td>\n",
       "      <td id=\"T_d3338_row11_col8\" class=\"data row11 col8\" >8.9062</td>\n",
       "      <td id=\"T_d3338_row11_col9\" class=\"data row11 col9\" >265.6875</td>\n",
       "      <td id=\"T_d3338_row11_col10\" class=\"data row11 col10\" >132.3125</td>\n",
       "      <td id=\"T_d3338_row11_col11\" class=\"data row11 col11\" >0.1094</td>\n",
       "      <td id=\"T_d3338_row11_col12\" class=\"data row11 col12\" >4.5781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row12\" class=\"row_heading level0 row12\" >mfcc/contrast/chroma</th>\n",
       "      <td id=\"T_d3338_row12_col0\" class=\"data row12 col0\" >42.1719</td>\n",
       "      <td id=\"T_d3338_row12_col1\" class=\"data row12 col1\" >7.4531</td>\n",
       "      <td id=\"T_d3338_row12_col2\" class=\"data row12 col2\" >61.7812</td>\n",
       "      <td id=\"T_d3338_row12_col3\" class=\"data row12 col3\" >52.6250</td>\n",
       "      <td id=\"T_d3338_row12_col4\" class=\"data row12 col4\" >290.9688</td>\n",
       "      <td id=\"T_d3338_row12_col5\" class=\"data row12 col5\" >138.1562</td>\n",
       "      <td id=\"T_d3338_row12_col6\" class=\"data row12 col6\" >5.4844</td>\n",
       "      <td id=\"T_d3338_row12_col7\" class=\"data row12 col7\" >0.2500</td>\n",
       "      <td id=\"T_d3338_row12_col8\" class=\"data row12 col8\" >21.8750</td>\n",
       "      <td id=\"T_d3338_row12_col9\" class=\"data row12 col9\" >334.2188</td>\n",
       "      <td id=\"T_d3338_row12_col10\" class=\"data row12 col10\" >274.5938</td>\n",
       "      <td id=\"T_d3338_row12_col11\" class=\"data row12 col11\" >0.1406</td>\n",
       "      <td id=\"T_d3338_row12_col12\" class=\"data row12 col12\" >9.6562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row13\" class=\"row_heading level0 row13\" >mfcc/contrast/centroid</th>\n",
       "      <td id=\"T_d3338_row13_col0\" class=\"data row13 col0\" >25.6250</td>\n",
       "      <td id=\"T_d3338_row13_col1\" class=\"data row13 col1\" >6.4531</td>\n",
       "      <td id=\"T_d3338_row13_col2\" class=\"data row13 col2\" >65.0625</td>\n",
       "      <td id=\"T_d3338_row13_col3\" class=\"data row13 col3\" >42.2969</td>\n",
       "      <td id=\"T_d3338_row13_col4\" class=\"data row13 col4\" >211.8125</td>\n",
       "      <td id=\"T_d3338_row13_col5\" class=\"data row13 col5\" >94.8438</td>\n",
       "      <td id=\"T_d3338_row13_col6\" class=\"data row13 col6\" >6.9375</td>\n",
       "      <td id=\"T_d3338_row13_col7\" class=\"data row13 col7\" >0.3594</td>\n",
       "      <td id=\"T_d3338_row13_col8\" class=\"data row13 col8\" >12.1250</td>\n",
       "      <td id=\"T_d3338_row13_col9\" class=\"data row13 col9\" >307.6250</td>\n",
       "      <td id=\"T_d3338_row13_col10\" class=\"data row13 col10\" >183.5469</td>\n",
       "      <td id=\"T_d3338_row13_col11\" class=\"data row13 col11\" >0.1406</td>\n",
       "      <td id=\"T_d3338_row13_col12\" class=\"data row13 col12\" >3.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row14\" class=\"row_heading level0 row14\" >mfcc/contrast/chroma/centroid</th>\n",
       "      <td id=\"T_d3338_row14_col0\" class=\"data row14 col0\" >38.9219</td>\n",
       "      <td id=\"T_d3338_row14_col1\" class=\"data row14 col1\" >7.1406</td>\n",
       "      <td id=\"T_d3338_row14_col2\" class=\"data row14 col2\" >84.9062</td>\n",
       "      <td id=\"T_d3338_row14_col3\" class=\"data row14 col3\" >48.2031</td>\n",
       "      <td id=\"T_d3338_row14_col4\" class=\"data row14 col4\" >273.6562</td>\n",
       "      <td id=\"T_d3338_row14_col5\" class=\"data row14 col5\" >125.4844</td>\n",
       "      <td id=\"T_d3338_row14_col6\" class=\"data row14 col6\" >6.7188</td>\n",
       "      <td id=\"T_d3338_row14_col7\" class=\"data row14 col7\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row14_col8\" class=\"data row14 col8\" >12.7969</td>\n",
       "      <td id=\"T_d3338_row14_col9\" class=\"data row14 col9\" >215.3125</td>\n",
       "      <td id=\"T_d3338_row14_col10\" class=\"data row14 col10\" >224.5000</td>\n",
       "      <td id=\"T_d3338_row14_col11\" class=\"data row14 col11\" >0.3125</td>\n",
       "      <td id=\"T_d3338_row14_col12\" class=\"data row14 col12\" >12.0312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row15\" class=\"row_heading level0 row15\" >mfcc/contrast/chroma/centroid/tonnetz</th>\n",
       "      <td id=\"T_d3338_row15_col0\" class=\"data row15 col0\" >43.3594</td>\n",
       "      <td id=\"T_d3338_row15_col1\" class=\"data row15 col1\" >6.7188</td>\n",
       "      <td id=\"T_d3338_row15_col2\" class=\"data row15 col2\" >96.4219</td>\n",
       "      <td id=\"T_d3338_row15_col3\" class=\"data row15 col3\" >63.2188</td>\n",
       "      <td id=\"T_d3338_row15_col4\" class=\"data row15 col4\" >363.2656</td>\n",
       "      <td id=\"T_d3338_row15_col5\" class=\"data row15 col5\" >127.0312</td>\n",
       "      <td id=\"T_d3338_row15_col6\" class=\"data row15 col6\" >6.9688</td>\n",
       "      <td id=\"T_d3338_row15_col7\" class=\"data row15 col7\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row15_col8\" class=\"data row15 col8\" >16.4531</td>\n",
       "      <td id=\"T_d3338_row15_col9\" class=\"data row15 col9\" >240.4688</td>\n",
       "      <td id=\"T_d3338_row15_col10\" class=\"data row15 col10\" >196.0469</td>\n",
       "      <td id=\"T_d3338_row15_col11\" class=\"data row15 col11\" >0.2031</td>\n",
       "      <td id=\"T_d3338_row15_col12\" class=\"data row15 col12\" >12.0781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row16\" class=\"row_heading level0 row16\" >mfcc/contrast/chroma/centroid/zcr</th>\n",
       "      <td id=\"T_d3338_row16_col0\" class=\"data row16 col0\" >40.8125</td>\n",
       "      <td id=\"T_d3338_row16_col1\" class=\"data row16 col1\" >7.2188</td>\n",
       "      <td id=\"T_d3338_row16_col2\" class=\"data row16 col2\" >79.9219</td>\n",
       "      <td id=\"T_d3338_row16_col3\" class=\"data row16 col3\" >56.6406</td>\n",
       "      <td id=\"T_d3338_row16_col4\" class=\"data row16 col4\" >303.3594</td>\n",
       "      <td id=\"T_d3338_row16_col5\" class=\"data row16 col5\" >137.6250</td>\n",
       "      <td id=\"T_d3338_row16_col6\" class=\"data row16 col6\" >5.8594</td>\n",
       "      <td id=\"T_d3338_row16_col7\" class=\"data row16 col7\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row16_col8\" class=\"data row16 col8\" >15.7188</td>\n",
       "      <td id=\"T_d3338_row16_col9\" class=\"data row16 col9\" >330.0781</td>\n",
       "      <td id=\"T_d3338_row16_col10\" class=\"data row16 col10\" >185.8281</td>\n",
       "      <td id=\"T_d3338_row16_col11\" class=\"data row16 col11\" >0.1875</td>\n",
       "      <td id=\"T_d3338_row16_col12\" class=\"data row16 col12\" >10.6719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d3338_level0_row17\" class=\"row_heading level0 row17\" >all_non-echonest</th>\n",
       "      <td id=\"T_d3338_row17_col0\" class=\"data row17 col0\" >61.7656</td>\n",
       "      <td id=\"T_d3338_row17_col1\" class=\"data row17 col1\" >9.2500</td>\n",
       "      <td id=\"T_d3338_row17_col2\" class=\"data row17 col2\" >117.3594</td>\n",
       "      <td id=\"T_d3338_row17_col3\" class=\"data row17 col3\" >102.3281</td>\n",
       "      <td id=\"T_d3338_row17_col4\" class=\"data row17 col4\" >564.2031</td>\n",
       "      <td id=\"T_d3338_row17_col5\" class=\"data row17 col5\" >221.0156</td>\n",
       "      <td id=\"T_d3338_row17_col6\" class=\"data row17 col6\" >10.9844</td>\n",
       "      <td id=\"T_d3338_row17_col7\" class=\"data row17 col7\" >0.2500</td>\n",
       "      <td id=\"T_d3338_row17_col8\" class=\"data row17 col8\" >27.1094</td>\n",
       "      <td id=\"T_d3338_row17_col9\" class=\"data row17 col9\" >207.1406</td>\n",
       "      <td id=\"T_d3338_row17_col10\" class=\"data row17 col10\" >294.1562</td>\n",
       "      <td id=\"T_d3338_row17_col11\" class=\"data row17 col11\" >0.3438</td>\n",
       "      <td id=\"T_d3338_row17_col12\" class=\"data row17 col12\" >24.7344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ee8132c610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = {\n",
    "    'LR': LogisticRegression(),\n",
    "    'kNN': KNeighborsClassifier(n_neighbors=200),\n",
    "    'SVCrbf': SVC(kernel='rbf'),\n",
    "    'SVCpoly1': SVC(kernel='poly', degree=1),\n",
    "    'linSVC1': SVC(kernel=\"linear\"),\n",
    "    'linSVC2': LinearSVC(),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    'DT': DecisionTreeClassifier(max_depth=5),\n",
    "    'RF': RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=10),\n",
    "    'MLP1': MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000),\n",
    "    'MLP2': MLPClassifier(hidden_layer_sizes=(200, 50), max_iter=2000),\n",
    "    'NB': GaussianNB(),\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_social': ('echonest', 'social_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "#    'echonest_audio/social': ('echonest', ('audio_features', 'social_features')),\n",
    "#    'echonest_all': ('echonest', ('audio_features', 'social_features', 'temporal_features')),\n",
    "}\n",
    "for name in features.columns.levels[0]:\n",
    "    feature_sets[name] = name\n",
    "feature_sets.update({\n",
    "    'mfcc/contrast': ['mfcc', 'spectral_contrast'],\n",
    "    'mfcc/contrast/chroma': ['mfcc', 'spectral_contrast', 'chroma_cens'],\n",
    "    'mfcc/contrast/centroid': ['mfcc', 'spectral_contrast', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid'],\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "    'all_non-echonest': list(features.columns.levels[0])\n",
    "})\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Multiple genres\n",
    "\n",
    "Todo:\n",
    "* Ignore rare genres? Count them higher up in the genre tree? On the other hand it's not much tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c29dfcb9954dd9bf16dc681475cedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "features:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27460\\115438056.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m'mfcc/contrast/chroma/centroid/tonnetz'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mfcc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spectral_contrast'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chroma_cens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spectral_centroid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tonnetz'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;34m'mfcc/contrast/chroma/centroid/zcr'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mfcc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spectral_contrast'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'chroma_cens'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'spectral_centroid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zcr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_classifiers_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_scores\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mipd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27460\\3011359019.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(classifiers, feature_sets, multi_label)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dim'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_sets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_sets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfset\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_sets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dim'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# tqdm_notebook(classifiers.items(), desc='classifiers', leave=False):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27460\\2405836066.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tracks, features, columns, multi_label, verbose)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Split in training, validation and testing sets.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6200\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6201\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6202\u001b[0m         ):\n\u001b[0;32m   6203\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6204\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    #LogisticRegression(),\n",
    "    'LR': OneVsRestClassifier(LogisticRegression()),\n",
    "    'SVC': OneVsRestClassifier(SVC()),\n",
    "    'MLP': MLPClassifier(max_iter=700),\n",
    "}\n",
    "\n",
    "feature_sets = {\n",
    "#    'echonest_audio': ('echonest', 'audio_features'),\n",
    "#    'echonest_temporal': ('echonest', 'temporal_features'),\n",
    "    'mfcc': 'mfcc',\n",
    "    'mfcc/contrast/chroma/centroid/tonnetz': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'tonnetz'],\n",
    "    'mfcc/contrast/chroma/centroid/zcr': ['mfcc', 'spectral_contrast', 'chroma_cens', 'spectral_centroid', 'zcr'],\n",
    "}\n",
    "\n",
    "scores, times = test_classifiers_features(classifiers, feature_sets, multi_label=True)\n",
    "\n",
    "ipd.display(format_scores(scores))\n",
    "ipd.display(times.style.format('{:.4f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Deep learning on raw audio\n",
    "\n",
    "Other architectures:\n",
    "* [Learning Features of Music from Scratch (MusicNet)](https://arxiv.org/abs/1611.09827), John Thickstun, Zaid Harchaoui, Sham Kakade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_onehot = LabelBinarizer().fit_transform(tracks['track', 'genre_top'])\n",
    "labels_onehot = pd.DataFrame(labels_onehot, index=tracks.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load audio samples in parallel using `multiprocessing` so as to maximize CPU usage when decoding MP3s and making some optional pre-processing. There are multiple ways to load a waveform from a compressed MP3:\n",
    "* librosa uses audioread in the backend which can use many native libraries, e.g. ffmpeg\n",
    "    * resampling is very slow --> use `kaiser_fast`\n",
    "    * does not work with multi-processing, for keras `fit_generator()`\n",
    "* pydub is a high-level interface for audio modification, uses ffmpeg to load\n",
    "    * store a temporary `.wav`\n",
    "* directly pipe ffmpeg output\n",
    "    * fastest method\n",
    "* [pyAV](https://github.com/mikeboers/PyAV) may be a fastest alternative by linking to ffmpeg libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just be sure that everything is fine. Multiprocessing is tricky to debug.\n",
    "utils.FfmpegLoader().load(utils.get_audio_path(AUDIO_DIR, 2))\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, utils.FfmpegLoader())\n",
    "SampleLoader(train, batch_size=2).__next__()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras parameters.\n",
    "NB_WORKER = len(os.sched_getaffinity(0))  # number of usables CPUs\n",
    "params = {'pickle_safe': True, 'nb_worker': NB_WORKER, 'max_q_size': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fully connected neural network\n",
    "\n",
    "* Two layers with 10 hiddens is no better than random, ~11%.\n",
    "\n",
    "Optimize data loading to be CPU / GPU bound, not IO bound. Larger batches means reduced training time, so increase batch time until memory exhaustion. Number of workers and queue size have no influence on speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=2000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "print('Dimensionality: {}'.format(loader.shape))\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(output_dim=1000, input_shape=loader.shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=64), train.size, nb_epoch=2, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=64), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=64), test.size, **params)\n",
    "#Y = model.predict_generator(SampleLoader(test, batch_size=64), test.size, **params);\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convolutional neural network\n",
    "\n",
    "* Architecture: [End-to-end learning for music audio](http://www.mirlab.org/conference_papers/International_Conference/ICASSP%202014/papers/p7014-dieleman.pdf), Sander Dieleman, Benjamin Schrauwen.\n",
    "* Missing: track segmentation and class averaging (majority voting)\n",
    "* Compared with log-scaled mel-spectrograms instead of strided convolution as first layer.\n",
    "* Larger net: http://benanne.github.io/2014/08/05/spotify-cnns.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = utils.FfmpegLoader(sampling_rate=16000)\n",
    "#loader = utils.LibrosaLoader(sampling_rate=16000)\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((-1, 1), input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv1D(128, 512, subsample_length=512))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "model.add(Conv1D(32, 8))\n",
    "print(model.output_shape)\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling1D(4))\n",
    "\n",
    "print(model.output_shape)\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=10), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=10), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=10), test.size, **params)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Deep learning on extracted audio features\n",
    "\n",
    "Look at:\n",
    "* Pre-processing in Keras: https://github.com/keunwoochoi/kapre\n",
    "* Convolutional Recurrent Neural Networks for Music Classification: https://github.com/keunwoochoi/icassp_2017\n",
    "* Music Auto-Tagger: https://github.com/keunwoochoi/music-auto_tagging-keras\n",
    "* Pre-processor: https://github.com/bmcfee/pumpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ConvNet on MFCC\n",
    "\n",
    "* Architecture: [Automatic Musical Pattern Feature Extraction Using Convolutional Neural Network](http://www.iaeng.org/publication/IMECS2010/IMECS2010_pp546-550.pdf), Tom LH. Li, Antoni B. Chan and Andy HW. Chun\n",
    "* Missing: track segmentation and majority voting.\n",
    "* Best seen: 17.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MfccLoader(utils.Loader):\n",
    "    raw_loader = utils.FfmpegLoader(sampling_rate=22050)\n",
    "    #shape = (13, 190)  # For segmented tracks.\n",
    "    shape = (13, 2582)\n",
    "    def load(self, filename):\n",
    "        import librosa\n",
    "        x = self.raw_loader.load(filename)\n",
    "        # Each MFCC frame spans 23ms on the audio signal with 50% overlap with the adjacent frames.\n",
    "        mfcc = librosa.feature.mfcc(x, sr=22050, n_mfcc=13, n_fft=512, hop_length=256)\n",
    "        return mfcc\n",
    "\n",
    "loader = MfccLoader()\n",
    "SampleLoader = utils.build_sample_loader(AUDIO_DIR, labels_onehot, loader)\n",
    "loader.load(utils.get_audio_path(AUDIO_DIR, 2))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Reshape((*loader.shape, 1),  input_shape=loader.shape))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(3, 13, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(15, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Conv2D(65, 1, 10, subsample=(1, 4)))\n",
    "model.add(Activation(\"relu\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(labels_onehot.shape[1]))\n",
    "model.add(Activation(\"softmax\"))\n",
    "print(model.output_shape)\n",
    "\n",
    "optimizer = keras.optimizers.SGD(1e-3)#lr=0.01, momentum=0.9, nesterov=True)\n",
    "#optimizer = keras.optimizers.Adam()#lr=1e-5)#\n",
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(SampleLoader(train, batch_size=16), train.size, nb_epoch=20, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(val, batch_size=16), val.size, **params)\n",
    "loss = model.evaluate_generator(SampleLoader(test, batch_size=16), test.size, **params)\n",
    "#Y = model.predict_generator(loader, test.size, pickle_safe=True, nb_worker=NB_WORKER, max_q_size=5)\n",
    "\n",
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
